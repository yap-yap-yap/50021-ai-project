{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3409943",
   "metadata": {},
   "source": [
    "# Doing vectorization of headline and article separately in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc4c0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer, regexp_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import dataset, generate_test_splits, score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2476ccb6",
   "metadata": {},
   "source": [
    "### Using the included data importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c5090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Total stances: 49972\n",
      "Total bodies: 1683\n",
      "Reading dataset\n",
      "Total stances: 25413\n",
      "Total bodies: 904\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset.DataSet(name='train')\n",
    "test_data = dataset.DataSet(name=\"competition_test\") # there's no stances for the non-competition test data??  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c88b88",
   "metadata": {},
   "source": [
    "### Converting imported data into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2497417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thousands of people have been duped by a fake news story claiming that Nasa has forecast a total blackout of earth for six days in December.\n",
      "\n",
      "The story, entitled \"Nasa Confirms Earth Will Experience 6 Days of Total Darkness in December 2014!\" originated from Huzlers.com, a website well known for publishing fake stories with sensational headlines.\n",
      "\n",
      "The bogus report read: \"Nasa has confirmed that the Earth will experience 6 days of almost complete darkness and will happen from the dates Tuesday the 16 – Monday the 22 in December. The world will remain, during these three days, without sunlight due to a solar storm, which will cause dust and space debris to become plentiful and thus, block 90% sunlight.\n",
      "\n",
      "\"The head of Nasa Charles Bolden who made the announcement and asked everyone to remain calm. This will be the product of a solar storm, the largest in the last 250 years for a period of 216 hours total.\n",
      "\n",
      "\"Despite the six days of darkness soon to come, officials say that the earth will not experience any major problems, since six days of darkness is nowhere near enough to cause major damage to anything.\"\n",
      "\n",
      "Adding on, the article also carried a made-up quote from Nasa scientist Earl Godoy, saying: \"We will solely rely on artificial light for the six days, which is not a problem at all.\"\n",
      "\n",
      "Many Twitter users believed the fake news report, and expressed their shock.\n",
      "\n",
      "We're going to have a complete 6 days of darkness due to a solar storm in Dec! SO NERVOUS ABOUT THIS! Ahhh. #ThePurge http://t.co/0L2Sis54hv— Janella (@hijanellamarie) October 26, 2014 6 days of total darkness in December? ? http://t.co/eTN60TnXft— Jammie Macaranas (@JammiePeach) October 26, 2014 \"NASA Confirms Earth will experience 6 Days of total DARKNESS in December 2014.\" Me: pic.twitter.com/xZG1xaxqdw— [Hiatus] TT (@sarangBCES) October 26, 2014 \"NASA Confirms Earth Will Experience 6 Days of Total Darkness in December 2014!\" omg what?— 查理 (@Chxrliecutie) October 26, 2014 islam know what this means im scared \"NASA Confirms Earth Will Experience 6 Days of Total Darkness in December 2014! http://t.co/GQGeGLmElZ\"— hiatus (@taobby) October 26, 2014\n",
      "\n",
      "The website has previously published a fake report about American rapper and actor Tupac Shakur, claiming that he is alive.\n",
      "\n",
      "RelatedHalloween 2014 on Friday the 13th for First Time in 666 Years Declared a HoaxShah Rukh Khan's Son Aryan and Aishwarya Rai Bachchan's Niece Navya's Leaked Sex Tape is FakeEbola Zombies: Victims 'Rising from the Dead' Fake News Story Goes Viral, Sparks Outrage on Social MediaEminem 'Quits Music After Checking Into Rehab Again For Heroin Addiction' is Hoax: Satirical Article Creates Stir on Social Media\n",
      "\n",
      "'Hairgate': iPhone 6 users encounter latest Apple problem after 'bendgate'\n",
      "\n",
      "unrelated\n"
     ]
    }
   ],
   "source": [
    "train_data_articles_df = pd.DataFrame({'Article': train_data.articles.values(), 'Body ID':train_data.articles.keys()} , index=train_data.articles.keys())\n",
    "train_data_stances_df = pd.DataFrame(train_data.stances)\n",
    "\n",
    "test_data_articles_df = pd.DataFrame({'Article': test_data.articles.values(), 'Body ID':test_data.articles.keys()} , index=test_data.articles.keys())\n",
    "test_data_stances_df = pd.DataFrame(test_data.stances)\n",
    "\n",
    "# checking out example output\n",
    "print(train_data_articles_df['Article'][154] + '\\n')\n",
    "print(train_data_stances_df['Headline'][158] + '\\n')\n",
    "print(train_data_stances_df['Stance'][158])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d38444",
   "metadata": {},
   "source": [
    "### Preprocessing: Tokenize and remove stopwords. \n",
    "\n",
    "More done later during vectorization when the dictionary size is cut short\n",
    "\n",
    "probably more that can be done\n",
    "\n",
    "TODO: put this all into importable utility functions so it can be put into the GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae78dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\b[^\\d\\W]+\\b') # regex can be improved but idk\n",
    "train_data_articles_df['article_cleaned'] = train_data_articles_df['Article'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "train_data_stances_df['headline_cleaned'] = train_data_stances_df['Headline'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "test_data_articles_df['article_cleaned'] = test_data_articles_df['Article'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "test_data_stances_df['headline_cleaned'] = test_data_stances_df['Headline'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "\n",
    "\n",
    "# remove_whitespace = r'\\s+'\n",
    "# train_data_articles_df['article_cleaned'] = train_data_articles_df['Article'].apply(lambda x: re.split(remove_whitespace, x))\n",
    "# train_data_stances_df['headline_cleaned'] = train_data_stances_df['Headline'].apply(lambda x: re.split(remove_whitespace, x))\n",
    "\n",
    "# exclude = r'[^/d/W]+'\n",
    "# train_data_articles_df['article_cleaned'] = train_data_articles_df['article_cleaned'].apply(lambda x: re.findall(exclude, x))\n",
    "# train_data_stances_df['headline_cleaned'] = train_data_stances_df['headline_cleaned'].apply(lambda x: re.findall(exclude, x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3f605e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIS Video: America’s Air Dropped Weapons Now in Our Hands\n",
      "['isis', 'video', 'america', 's', 'air', 'dropped', 'weapons', 'now', 'in', 'our', 'hands']\n",
      "discuss\n"
     ]
    }
   ],
   "source": [
    "print(train_data_stances_df['Headline'][154])\n",
    "print(train_data_stances_df['headline_cleaned'][154])\n",
    "print(train_data_stances_df['Stance'][154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8433fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_words = ['http', 'twitter', 'com', 'pic', 'co']\n",
    "month_words = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'novemeber', 'december']\n",
    "# TODO: think of more for these\n",
    "\n",
    "my_banned_words = stopwords.words('english') + website_words + month_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1c666b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(string):\n",
    "    output = []\n",
    "    for word in string:\n",
    "        if word not in my_banned_words:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "train_data_articles_df['article_cleaned'] =  train_data_articles_df['article_cleaned'].apply(lambda x: remove_stopwords(x))\n",
    "train_data_stances_df['headline_cleaned'] =  train_data_stances_df['headline_cleaned'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "test_data_articles_df['article_cleaned'] =  test_data_articles_df['article_cleaned'].apply(lambda x: remove_stopwords(x))\n",
    "test_data_stances_df['headline_cleaned'] =  test_data_stances_df['headline_cleaned'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5771e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['net', 'extra', 'back', 'dead', 'catholic', 'priest', 'claims', 'god', 'female']\n",
      "['net', 'extra', 'back', 'dead', 'catholic', 'priest', 'claim', 'god', 'female']\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "print(train_data_stances_df['headline_cleaned'][24])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(string):\n",
    "    output = []\n",
    "    for word in string:\n",
    "        output.append(lemmatizer.lemmatize(word))\n",
    "    return output\n",
    "    \n",
    "train_data_articles_df['article_cleaned'] =  train_data_articles_df['article_cleaned'].apply(lambda x: lemmatize_tokens(x))\n",
    "train_data_stances_df['headline_cleaned'] =  train_data_stances_df['headline_cleaned'].apply(lambda x: lemmatize_tokens(x))\n",
    "\n",
    "test_data_articles_df['article_cleaned'] =  test_data_articles_df['article_cleaned'].apply(lambda x: lemmatize_tokens(x))\n",
    "test_data_stances_df['headline_cleaned'] =  test_data_stances_df['headline_cleaned'].apply(lambda x: lemmatize_tokens(x))\n",
    "\n",
    "print(train_data_stances_df['headline_cleaned'][24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c828b2d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISIS Video: America’s Air Dropped Weapons Now in Our Hands\n",
      "['isi', 'video', 'america', 'air', 'dropped', 'weapon', 'hand']\n"
     ]
    }
   ],
   "source": [
    "print(train_data_stances_df['Headline'][154])\n",
    "print(train_data_stances_df['headline_cleaned'][154])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1b80325",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('processed'):\n",
    "    os.mkdir('processed')\n",
    "\n",
    "train_data_articles_df.to_csv(\"processed/processed_train_articles.csv\")\n",
    "train_data_stances_df.to_csv(\"processed/processed_train_stances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7976c",
   "metadata": {},
   "source": [
    "\n",
    " ### Strategy: calculate tf score for headline and article separately, concatenate those two together (final feature count = 2x size of vocabulary) + tfidf cosine similarity \n",
    "\n",
    "this means have to save the vocab so that we can vectorize the GUI input w.r.t this vocab. Or not the gui prediction won't work due to difference in number of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ae73d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate vocabulary of articles + headlines\n",
    "vocab_total = Counter()\n",
    "\n",
    "for line in train_data_articles_df['article_cleaned'].values:\n",
    "    vocab_total.update(line)\n",
    "for line in train_data_stances_df['headline_cleaned'].values:\n",
    "    vocab_total.update(line)\n",
    "\n",
    "num_features = 5000\n",
    "vocab_counts = vocab_total.most_common(num_features)\n",
    "vocab = []\n",
    "for word, _ in vocab_counts:\n",
    "    vocab.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be437a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  5  6  7  8  9 10 11 13]\n",
      "[2102 1120 2414   75  298  720 1340  931 2448 2032]\n"
     ]
    }
   ],
   "source": [
    "stance_to_number = {\n",
    "    \"agree\": 0,\n",
    "    \"disagree\": 1,\n",
    "    \"discuss\": 2,\n",
    "    \"unrelated\": 3\n",
    "}\n",
    "\n",
    "\n",
    "def match_id(articles_df, headlines_df, body_ids):\n",
    "    # instead of concatenating article and headline, just output 2 lists. \n",
    "    # since they are added at the same time the indexes are the same i.e. body id matches\n",
    "    features_articles = []\n",
    "    features_headlines = []\n",
    "    labels = []\n",
    "    \n",
    "    for body_id in body_ids:\n",
    "        article = articles_df[articles_df['Body ID'] == body_id]['article_cleaned'].values[0]\n",
    "    #     print(article)\n",
    "        headlines = headlines_df[headlines_df['Body ID'] == body_id]['headline_cleaned'].values\n",
    "    #     print(headlines)\n",
    "        stances = headlines_df[headlines_df['Body ID'] == body_id]['Stance'].values\n",
    "    #     print(stances)\n",
    "        for headline, stance in zip(headlines, stances):\n",
    "            features_articles.append(article)\n",
    "            features_headlines.append(headline)\n",
    "            labels.append(stance_to_number[stance])\n",
    "    return features_articles, features_headlines, labels\n",
    "\n",
    "body_ids = train_data_articles_df['Body ID'].copy().values\n",
    "print(body_ids[0:10])\n",
    "np.random.seed(42) # set your seed\n",
    "np.random.shuffle(body_ids) # randomise it here and then do the train/val split later directly. If randomised later then validation and training set each will draw from their own datasets\n",
    "print(body_ids[0:10])\n",
    "features_articles, features_headlines, labels = match_id(train_data_articles_df, train_data_stances_df, body_ids) # article, headline and stances are retrieved at the same time so splitting later is fine\n",
    "\n",
    "# TODO: split train/val evenly between each type of stance?\n",
    "\n",
    "test_body_ids = test_data_articles_df['Body ID'].copy().values\n",
    "# don't randomise test set\n",
    "test_features_articles, test_features_headlines, test_labels = match_id(test_data_articles_df, test_data_stances_df, test_body_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7763744f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uk', 'confirmed', 'video', 'showing', 'beheading', 'aid', 'worker', 'david', 'haines']\n",
      "['unconfirmed', 'report', 'saying', 'isi', 'uk', 'hostage', 'david', 'haines', 'beheaded']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(features_articles[0])\n",
    "print(features_headlines[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f65430d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49972, 5000)\n",
      "(49972, 5000)\n"
     ]
    }
   ],
   "source": [
    "# dummy preprocessor and tokenizer because already did that above. not going to change it up to fit this format\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "vectorizer = CountVectorizer(preprocessor=dummy, tokenizer=dummy, vocabulary=vocab) # try messing with min_df param: can remove twitter handles and such\n",
    "features_articles_counts = vectorizer.fit_transform(features_articles)\n",
    "features_headlines_counts = vectorizer.fit_transform(features_headlines)\n",
    "\n",
    "test_features_articles_counts = vectorizer.fit_transform(test_features_articles)\n",
    "test_features_headlines_counts = vectorizer.fit_transform(test_features_headlines)\n",
    "\n",
    "print(features_articles_counts.shape)\n",
    "print(features_headlines_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "804149ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isi' 'u' 'report' 'said' 'say' 'video' 'apple' 'state' 'claim' 'foley'\n",
      " 'man' 'islamic' 'journalist' 'james' 'watch' 'michael' 'american' 'new'\n",
      " 'kim' 'haram' 'boko' 'brown' 'militant' 'ebola' 'leader' 'audio' 'year'\n",
      " 'jong' 'shot' 'fighter' 'killed' 'reportedly' 'shooting' 'missing'\n",
      " 'official' 'girl' 'un' 'woman' 'job' 'steve' 'al' 'one' 'time' 'news'\n",
      " 'kidnapped' 'dead' 'north' 'medium' 'syria' 'could']\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out()[0:50])\n",
    "print(np.where(vectorizer.get_feature_names_out() == \"relatedhalloween\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334fa9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5634b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# calculating tf and tfidf. \n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True)\n",
    "\n",
    "features_articles_tf = tf_transformer.fit_transform(features_articles_counts)\n",
    "features_headlines_tf = tf_transformer.fit_transform(features_headlines_counts)\n",
    "features_articles_tfidf = tfidf_transformer.fit_transform(features_articles_counts)\n",
    "features_headlines_tfidf = tfidf_transformer.fit_transform(features_headlines_counts)\n",
    "\n",
    "test_features_articles_tf = tf_transformer.fit_transform(test_features_articles_counts)\n",
    "test_features_headlines_tf = tf_transformer.fit_transform(test_features_headlines_counts)\n",
    "test_features_articles_tfidf = tfidf_transformer.fit_transform(test_features_articles_counts)\n",
    "test_features_headlines_tfidf = tfidf_transformer.fit_transform(test_features_headlines_counts)\n",
    "\n",
    "print(type(features_articles_tfidf[0].toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d5a5280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10001)\n"
     ]
    }
   ],
   "source": [
    "# concatenate as headline tf + tfidf cosine similarity + article tf\n",
    "\n",
    "def generate_feature_vector(articles_tf, headlines_tf, articles_tfidf, headlines_tfidf):\n",
    "    output = []\n",
    "    for article_tf, headline_tf, article_tfidf, headline_tfidf in zip(articles_tf, headlines_tf, articles_tfidf, headlines_tfidf):\n",
    "        article_tf = article_tf.toarray()\n",
    "        headline_tf = headline_tf.toarray()\n",
    "        article_tfidf = article_tfidf.toarray()\n",
    "        headline_tfidf = headline_tfidf.toarray()\n",
    "        \n",
    "        cosine = cosine_similarity(article_tfidf, headline_tfidf)\n",
    "        output.append(np.concatenate([headline_tf, cosine, article_tf], axis=1))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "            \n",
    "features = generate_feature_vector(features_articles_tf, features_headlines_tf, features_articles_tfidf, features_headlines_tfidf)\n",
    "test_features = generate_feature_vector(test_features_articles_tf, test_features_headlines_tf, test_features_articles_tfidf, test_features_headlines_tfidf)\n",
    "\n",
    "print(features[0].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8190dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW do the train val split. \n",
    "# Vectorise and get bag of words for both train + val first so that the features are the same length\n",
    "# can also instead generate a dictionary beforehand to pass into the vectorizer\n",
    "\n",
    "train_percentage = 0.8\n",
    "num_samples = len(features)\n",
    "split_index = int(train_percentage*num_samples)\n",
    "train_features = features[:split_index]\n",
    "val_features = features[split_index:]\n",
    "train_labels = labels[:split_index]\n",
    "val_labels = labels[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf786c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the vectors\n",
    "# train_features_tfidf_nparray = train_features_tfidf.toarray()\n",
    "# test_features_tfidf_nparray = test_features_tfidf.toarray()\n",
    "\n",
    "# np.savetxt(\"processed/vector_train_features_tdidf.txt\", train_features_tfidf_nparray)\n",
    "# np.savetxt(\"processed/vector_test_features_tdidf.txt\", test_features_tfidf_nparray)\n",
    "# >22GB\n",
    "\n",
    "# the file size is so big for the vectorized array \n",
    "# i think it's better to save the data as just list of sentences and load them, \n",
    "# then do the vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c40926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features=in_dim, out_features=2500) # TODO: mess with the hidden layer sizes\n",
    "        self.fc2 = nn.Linear(in_features=2500, out_features=1000)\n",
    "        self.fc3 = nn.Linear(in_features=1000, out_features=100)\n",
    "        self.fc4 = nn.Linear(in_features=100, out_features=out_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6941800",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimensions = 2*num_features + 1\n",
    "out_dimensions = 4\n",
    "\n",
    "model = MultiLayerPerceptron(input_dimensions, out_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58fa15eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0779b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c73930a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    }
   ],
   "source": [
    "# for batches \n",
    "batch_size = 32\n",
    "\n",
    "# train_features_tfidf_array = train_features_tfidf.toarray()\n",
    "# val_features_tfidf_array = val_features_tfidf.toarray()\n",
    "# test_features_tfidf_array = test_features_tfidf.toarray()\n",
    "\n",
    "\n",
    "train_iterator = data.DataLoader([[train_features[i], train_labels[i]] for i in range(len(train_labels))],\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=2)\n",
    "\n",
    "val_iterator = data.DataLoader([[val_features[i], val_labels[i]] for i in range(len(val_labels))],\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=2)\n",
    "test_iterator = data.DataLoader([[test_features[i], test_labels[i]] for i in range(len(test_labels))],\n",
    "                                 shuffle=False,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=2)\n",
    "\n",
    "train_iterator_size = len(train_iterator)\n",
    "val_iterator_size = len(val_iterator)\n",
    "print(train_iterator_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57c89d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y, label):\n",
    "    top_pred = y.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(label.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / label.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9433456",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1:\n",
      "train loss = 0.073; train acc = 97.331%\n",
      "val loss = 0.262; val acc = 92.222%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2:\n",
      "train loss = 0.040; train acc = 98.525%\n",
      "val loss = 0.345; val acc = 92.154%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3:\n",
      "train loss = 0.027; train acc = 99.090%\n",
      "val loss = 0.302; val acc = 92.732%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4:\n",
      "train loss = 0.019; train acc = 99.352%\n",
      "val loss = 0.347; val acc = 92.682%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5:\n",
      "train loss = 0.014; train acc = 99.513%\n",
      "val loss = 0.360; val acc = 92.882%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "overall_train_loss = []\n",
    "overall_val_loss = []\n",
    "overall_train_acc = []\n",
    "overall_val_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for x, label in tqdm(train_iterator, desc=f\"Epoch {epoch+1} training\", leave=False):        \n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        x = x.float() \n",
    "        label = label.long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y = model(x)\n",
    "        y = y.view(-1,4)\n",
    "        \n",
    "        loss = criterion(y, label)\n",
    "        acc = calculate_accuracy(y, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc.item()\n",
    "        \n",
    "    train_loss /= train_iterator_size\n",
    "    train_acc /= train_iterator_size\n",
    "    \n",
    "    overall_train_loss.append(train_loss)\n",
    "    overall_train_acc.append(train_acc)\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for x, label in tqdm(val_iterator, desc=f\"Epoch {epoch+1} validating\", leave=False):\n",
    "            x = x.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            x = x.float() \n",
    "            label = label.long()\n",
    "\n",
    "            y = model(x)\n",
    "            y = y.view(-1,4)\n",
    "            \n",
    "            loss = criterion(y, label)\n",
    "            acc = calculate_accuracy(y, label)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc.item()\n",
    "            \n",
    "    val_loss /= val_iterator_size\n",
    "    val_acc /= val_iterator_size\n",
    "    \n",
    "    overall_val_loss.append(val_loss)\n",
    "    overall_val_acc.append(val_acc)\n",
    "    \n",
    "    print(f\"epoch {epoch+1}:\")\n",
    "    print(f\"train loss = {train_loss:.3f}; train acc = {train_acc*100:.3f}%\")\n",
    "    print(f\"val loss = {val_loss:.3f}; val acc = {val_acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21fc72bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc (train_loss, val_loss, train_acc, val_acc):\n",
    "  fig, ax = plt.subplots(1,2)\n",
    "  \n",
    "  ax[0].set_title(\"Loss\")\n",
    "  ax[0].plot(train_loss, label=\"Training\")\n",
    "  ax[0].plot(val_loss, label=\"Validation\")\n",
    "  ax[0].legend()\n",
    "\n",
    "\n",
    "  \n",
    "  ax[1].set_title(\"Accuracy\")\n",
    "  ax[1].plot(train_acc, label=\"Training\")\n",
    "  ax[1].plot(val_acc, label=\"Validation\")\n",
    "  ax[1].legend()\n",
    "\n",
    "\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22ead512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_acc(overall_train_loss, overall_val_loss, overall_train_acc, overall_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e6fc661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "test_labels_predicted = []\n",
    "with torch.no_grad():\n",
    "    for x, label in tqdm(test_iterator, desc=f\"testing\", leave=False):\n",
    "        x = x.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        x = x.float() \n",
    "        label = label.long()\n",
    "\n",
    "        y = model(x)\n",
    "        \n",
    "        test_labels_predicted.append(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea0116dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_stance = {\n",
    "    0: \"agree\",\n",
    "    1: \"disagree\",\n",
    "    2: \"discuss\",\n",
    "    3: \"unrelated\"\n",
    "}\n",
    "test_stances = []\n",
    "\n",
    "for label in test_labels:\n",
    "    test_stances.append(number_to_stance[int(label)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f292adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "test_stances_pred = []\n",
    "print(test_labels_predicted[0].shape)\n",
    "for i in test_labels_predicted:\n",
    "    for j in i:\n",
    "        top_pred = j[0].argmax(0, keepdim=True)\n",
    "        test_stances_pred.append(number_to_stance[top_pred.item()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e947314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(len(test_stances_pred) == len(test_stances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "16be602d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------\n",
      "|           |   agree   | disagree  |  discuss  | unrelated |\n",
      "-------------------------------------------------------------\n",
      "|   agree   |    934    |    24     |    844    |    101    |\n",
      "-------------------------------------------------------------\n",
      "| disagree  |    263    |    28     |    325    |    81     |\n",
      "-------------------------------------------------------------\n",
      "|  discuss  |    728    |    40     |   3444    |    252    |\n",
      "-------------------------------------------------------------\n",
      "| unrelated |    783    |    150    |   1849    |   15567   |\n",
      "-------------------------------------------------------------\n",
      "Score: 8853.75 out of 11651.25\t(75.98970067589315%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.98970067589315"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.report_score(test_stances, test_stances_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "674d12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mlp-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8eef98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-1",
   "language": "python",
   "name": "gpu-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
